{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "grid_size = (50, 50)\n",
    "np.random.seed(123)\n",
    "criminality = np.random.rand(*grid_size) # Define the initial criminality for every cell\n",
    "education = np.random.rand(*grid_size) # Define the education for every cell (here fixed, but can be linked to data in final model)\n",
    "income = np.random.rand(*grid_size) # Define the income for every cell (here fixed, but can be linked to data in final model)\n",
    "alpha = 0.3 # Assign weight for influence of criminality in own neighbourhood\n",
    "beta = 1 - alpha # Assign weight for influence of criminality in other neighbourhoods \n",
    "influence_diff = 0 # Assign weight for difference in influence of \"bad\" neighbourhoods compared to \"good\" neighbourhoods\n",
    "percolation_threshold = 0.5 # Define the percolation threshold to later calculate the giant component\n",
    "police_threshold = 0.7 # Set the threshold of criminality for police intervention\n",
    "police_effect = 0.3 # Decide by how much criminality is reduced in a cell when police acts\n",
    "redistribution_frac = 0.7 # Decide how much of the criminality is redistributed to neighbouring cells\n",
    "police_units = 15 # Define the number of available police units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "states  = [0, 0.5, 1]\n",
    "criminality = np.random.choice(states, size=grid_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we set up the model such that, in each time period, we update the criminality level $C$ of each cell based on the transition function:\n",
    "\n",
    "$$ C_{t+1} =  \\alpha C_t + (\\beta (1 - \\gamma)) M + \\frac{\\beta}{2} L$$\n",
    "\n",
    "where:\n",
    "- $\\alpha$ controls the sensitivity of the new level of criminality to the cell-self old criminality;\n",
    "- $\\beta$ controls the sensitivity to the neighbors situation;\n",
    "- $\\gamma$ calibrates the dependence of sensitivity to neighbors based on education and income;\n",
    "- $M$ represents the mean criminality of neighbors with more criminality than the cell of interest;\n",
    "- $L$ the ones with less criminality.\n",
    "\n",
    "This distinction (between $M$ and $L$) is necessary, since a higher education/income should reduce the sensitivity to higher criminality, but not to lower.\n",
    "$\\beta$ is scaled by $\\frac{1}{2}$ to make it comparable on average to $\\beta (1 - \\gamma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to run simulation\n",
    "\n",
    "def update_cell(x, y, criminality, education, income, influence_diff): # Update the criminality of a cell based on its neighbours and itself\n",
    "\n",
    "    current_state = criminality[x, y]\n",
    "    neighbors = criminality[max(0, x-1):x+2, max(0,y-1):y+2] # Get the 8 neighbours of the cell\n",
    "    neighbors = np.delete(neighbors, (neighbors.shape[0] // 2, neighbors.shape[1] // 2)) # Remove the cell itself from the neighbours\n",
    "\n",
    "    # Here we distinguish between neighbours with more criminality and neighbours with less criminality\n",
    "    less_crim_influence = np.mean(neighbors[neighbors <= current_state]) if np.any(neighbors <= current_state) else 0\n",
    "    more_crim_influence = np.mean(neighbors[neighbors > current_state]) if np.any(neighbors > current_state) else 0\n",
    "\n",
    "    gamma = np.mean([education[x, y], income[x, y]]) # Here we calculate the average sensitivity of the cell to \"external\" criminality, so that higher education/income result in lower sensitivity (following line)\n",
    "\n",
    "    # Here we calculate the influence of neighbors distinguishing between more and less criminality (compared to the cell itself) because higher education/income should lower the sensitivity to more criminality but not to less criminality\n",
    "    weight_more = (beta * np.clip(1 - gamma, 0.1, 0.9)) + influence_diff # We clip the value to avoid the weight to be 0\n",
    "    weight_less = (beta / 2) - influence_diff\n",
    "\n",
    "    # Here we calculate the new criminality of the cell based on the criminality of the cell itself and the influence of the neighbours\n",
    "    new_state = (\n",
    "        alpha * current_state +\n",
    "        weight_more * more_crim_influence +\n",
    "        weight_less * less_crim_influence\n",
    "    )\n",
    "    return np.clip(new_state, 0, 1)\n",
    "\n",
    "def update_grid_nopolice(criminality, education, income, influence_diff): # Update the criminality of the whole grid based on the update_cell function\n",
    "\n",
    "    new_criminality = np.zeros_like(criminality)\n",
    "    for x in range(grid_size[0]):\n",
    "        for y in range(grid_size[1]):\n",
    "            new_criminality[x, y] = update_cell(x, y, criminality, education, income, influence_diff)\n",
    "    \n",
    "    return new_criminality\n",
    "\n",
    "def update_cell_withbuildup(x, y, criminality, education, income, influence_diff, buildup): # Update the criminality of a cell based on its neighbours and itself\n",
    "\n",
    "    current_state = criminality[x, y]\n",
    "    neighbors = criminality[max(0, x-1):x+2, max(0,y-1):y+2] # Get the 8 neighbours of the cell\n",
    "    neighbors = np.delete(neighbors, (neighbors.shape[0] // 2, neighbors.shape[1] // 2)) # Remove the cell itself from the neighbours\n",
    "\n",
    "    # Here we distinguish between neighbours with more criminality and neighbours with less criminality\n",
    "    less_crim_influence = np.mean(neighbors[neighbors <= current_state - buildup]) if np.any(neighbors <= current_state) else 0\n",
    "    more_crim_influence = np.mean(neighbors[neighbors > current_state + buildup]) if np.any(neighbors > current_state) else 0\n",
    "\n",
    "    gamma = np.mean([education[x, y], income[x, y]]) # Here we calculate the average sensitivity of the cell to \"external\" criminality, so that higher education/income result in lower sensitivity (following line)\n",
    "\n",
    "    # Here we calculate the influence of neighbors distinguishing between more and less criminality (compared to the cell itself) because higher education/income should lower the sensitivity to more criminality but not to less criminality\n",
    "    weight_more = (beta * np.clip(1 - gamma, 0.1, 0.9)) + influence_diff # We clip the value to avoid the weight to be 0\n",
    "    weight_less = (beta / 2) - influence_diff\n",
    "\n",
    "    # Here we calculate the new criminality of the cell based on the criminality of the cell itself and the influence of the neighbours\n",
    "    new_state = (\n",
    "        alpha * current_state +\n",
    "        weight_more * more_crim_influence +\n",
    "        weight_less * less_crim_influence\n",
    "    )\n",
    "    return np.clip(new_state, 0, 1)\n",
    "\n",
    "def update_grid_nopolice_withbuildup(criminality, education, income, influence_diff, buildup): # Update the criminality of the whole grid based on the update_cell function\n",
    "\n",
    "    new_criminality = np.zeros_like(criminality)\n",
    "    for x in range(grid_size[0]):\n",
    "        for y in range(grid_size[1]):\n",
    "            new_criminality[x, y] = update_cell_withbuildup(x, y, criminality, education, income, influence_diff, buildup)\n",
    "    \n",
    "    return new_criminality\n",
    "\n",
    "def update_grid_withpolice(criminality, education, income, influence_diff, police_threshold, police_effect, redistribution_frac, police_units): # Update the criminality of the whole grid based on the update_cell function and police intervention\n",
    "\n",
    "    new_criminality = np.zeros_like(criminality)\n",
    "    for x in range(grid_size[0]):\n",
    "        for y in range(grid_size[1]):\n",
    "            new_criminality[x, y] = update_cell(x, y, criminality, education, income, influence_diff)\n",
    "\n",
    "    new_criminality, mask = police(new_criminality, police_threshold, police_effect, redistribution_frac, police_units) # Apply police intervention and save the mask grid to visualize the intervention\n",
    "    \n",
    "    return new_criminality, mask\n",
    "\n",
    "def giant_component(criminality, percolation_threshold): # Compute the size of the giant component in the criminality grid (as fraction of the grid size)\n",
    "\n",
    "    perc_cells = criminality >= percolation_threshold # Output the grid with True value for cells with criminality above the percolation threshold\n",
    "    labeled_crim, num_features = label(perc_cells) # Label the connected components in the grid (every cluster of connected cells gets a unique label)\n",
    "\n",
    "    components = np.bincount(labeled_crim.ravel()) # Count the number of cells in each connected component\n",
    "    giant_component = np.max(components[1:]) if len(components) > 1 else 0 # Get the size of the largest connected component\n",
    "\n",
    "    return giant_component / criminality.size\n",
    "\n",
    "def police(criminality, police_threshold, police_effect, redistribution_frac, police_units): # Apply police intervention to the criminality grid\n",
    "\n",
    "    criminality_copy = criminality.copy()\n",
    "    mask = np.zeros_like(criminality, dtype=bool) # Generate an equal grid to save location of police interventions to visualize later\n",
    "\n",
    "    police_candidates = np.argwhere(criminality > police_threshold) # Get the coordinates of cells with criminality above the police threshold\n",
    "    police_candidates = sorted(police_candidates, key=lambda x: criminality[x[0], x[1]], reverse=True) # Sort the cells by descending criminality\n",
    "\n",
    "    interventions = police_candidates[:police_units] # Select the cells where police will act based on the number of available police units\n",
    "\n",
    "    for x, y in interventions:\n",
    "        mask[x, y] = True\n",
    "        criminality_copy[x, y] = np.clip(criminality[x, y] - police_effect, 0, 1) # Reduce the criminality of the cell by the police effect\n",
    "\n",
    "        neighbors_x = range(max(0, x-1), min(grid_size[0], x+2))\n",
    "        neighbors_y = range(max(0, y-1), min(grid_size[1], y+2))\n",
    "\n",
    "        # Redistribute the criminality of the cell to its neighbours according to the redistribution fraction\n",
    "        for nx in neighbors_x:\n",
    "            for ny in neighbors_y:\n",
    "                if (nx, ny) == (x, y):\n",
    "                    continue\n",
    "                criminality_copy[nx, ny] += (police_effect * redistribution_frac) / (len(neighbors_x) * len(neighbors_y) - 1)\n",
    "    \n",
    "    return criminality_copy, mask\n",
    "\n",
    "def detect_avelanche(criminality, new_criminality, threshold): # Detect if an avelanche happened in the grid\n",
    "\n",
    "    diff = np.abs(new_criminality - criminality)\n",
    "    affected_cells = diff > threshold # Get the cells where the difference in criminality is above the threshold\n",
    "\n",
    "    labeled_avalanches, num_features = label(affected_cells) # Label the avelanches\n",
    "\n",
    "    avalanche_sizes = np.bincount(labeled_avalanches.ravel())[1:] # Count the number of cells in each avelanche\n",
    "\n",
    "    return avalanche_sizes, labeled_avalanches\n",
    "\n",
    "def track_avalanches(criminality, education, income, influence_diff, time_steps, threshold):\n",
    "\n",
    "    all_avelanches_sizes = []\n",
    "    for step in range(time_steps): # In each time step, update the grid and detect avelanches and their sizes\n",
    "        new_criminality = update_grid_nopolice(criminality, education, income, influence_diff)\n",
    "        avalanche_sizes, labeled_avalanches = detect_avelanche(criminality, new_criminality, threshold)\n",
    "        all_avelanches_sizes.extend(avalanche_sizes)\n",
    "        criminality = new_criminality.copy()\n",
    "\n",
    "    return all_avelanches_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def update_grid_nopolice(criminality, education, income, influence_diff, alpha=0.3, beta=0.7):\n",
    "    padded_crim = np.pad(criminality, pad_width=1, mode='constant', constant_values=np.nan)\n",
    "    neighborhoods = sliding_window_view(padded_crim, (3, 3))\n",
    "    neighbors = neighborhoods.reshape(*criminality.shape, 9)\n",
    "    neighbors = np.delete(neighbors, 4, axis=2) \n",
    "    \n",
    "    current = criminality[..., np.newaxis]\n",
    "    \n",
    "    more_mask = neighbors > current\n",
    "    less_mask = neighbors <= current\n",
    "    sum_more = np.nansum(neighbors * more_mask, axis=2)\n",
    "    count_more = np.nansum(more_mask, axis=2)\n",
    "    more_infl = np.divide(sum_more, count_more, out=np.zeros_like(sum_more), where=count_more!=0)\n",
    "    \n",
    "    sum_less = np.nansum(neighbors * less_mask, axis=2)\n",
    "    count_less = np.nansum(less_mask, axis=2)\n",
    "    less_infl = np.divide(sum_less, count_less, out=np.zeros_like(sum_less), where=count_less!=0)\n",
    "    gamma = (education + income) / 2\n",
    "    w_more = beta * np.clip(1 - gamma, 0.1, 0.9) + influence_diff\n",
    "    w_less = beta/2 - influence_diff\n",
    "    new_crim = alpha*criminality + w_more*more_infl + w_less*less_infl\n",
    "    \n",
    "    return np.clip(new_crim, 0, 1)\n",
    "\n",
    "def update_grid_withpolice(criminality, education, income, influence_diff, police_threshold, police_effect, redistribution_frac, police_units):\n",
    "    new_criminality = update_grid_nopolice(criminality, education, income, influence_diff)\n",
    "\n",
    "    new_criminality, mask = police(new_criminality, police_threshold, police_effect, redistribution_frac, police_units) # Apply police intervention and save the mask grid to visualize the intervention\n",
    "    \n",
    "    return new_criminality, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Define functions to run simulation\n",
    "\n",
    "def update_cell(x, y, criminality, education, income): # Update the criminality of a cell based on its neighbours nad itself\n",
    "\n",
    "    current_state = criminality[x, y]\n",
    "    neighbors = criminality[max(0, x-1):x+2, max(0,y-1):y+2] # Get the 8 neighbours of the cell\n",
    "    neighbors = np.delete(neighbors, (neighbors.shape[0] // 2, neighbors.shape[1] // 2)) # Remove the cell itself from the neighbours\n",
    "\n",
    "    # Here we distinguish between neighbours with more criminality and neighbours with less criminality\n",
    "    less_crim_influence = np.mean(neighbors[neighbors <= current_state]) if np.any(neighbors <= current_state) else 0\n",
    "    more_crim_influence = np.mean(neighbors[neighbors > current_state]) if np.any(neighbors > current_state) else 0\n",
    "\n",
    "    gamma = np.mean([education[x, y], income[x, y]]) # Here we calculate the average sensitivity of the cell to \"external\" criminality, so that higher education/income result in lower sensitivity (following line)\n",
    "\n",
    "    # Here we calculate the influence of neighbors distinguishing between more and less criminality (compared to the cell itself) because higher education/income should lower the sensitivity to more criminality but not to less criminality\n",
    "    weight_more = beta * np.clip(1 - gamma, 0.1, 0.9) # We clip the value to avoid the weight to be 0\n",
    "    weight_less = beta / 2\n",
    "\n",
    "    # Here we calculate the new criminality of the cell based on the criminality of the cell itself and the influence of the neighbours\n",
    "    new_state = (\n",
    "        current_state +\n",
    "        weight_more * more_crim_influence +\n",
    "        weight_less * less_crim_influence\n",
    "    )\n",
    "\n",
    "    if new_state > 0.66:\n",
    "        new_state = 1\n",
    "    elif new_state > 0.33:\n",
    "        new_state = 0.5\n",
    "    else:\n",
    "        new_state = 0\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "def update_grid(criminality, education, income): # Update the criminality of the whole grid based on the update_cell function\n",
    "    new_criminality = np.zeros_like(criminality)\n",
    "    for x in range(grid_size[0]):\n",
    "        for y in range(grid_size[1]):\n",
    "            new_criminality[x, y] = update_cell(x, y, criminality, education, income)\n",
    "    return new_criminality\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Define functions to run simulation\n",
    "\n",
    "sensitivity = (education + income) / 2 # Define the sensitivity of every cell to criminality\n",
    "\n",
    "def moore_neighbors(x, y, grid):\n",
    "\n",
    "    neighbors = []\n",
    "    for i in range(max(0, x - 1), min(grid.shape[0], x + 2)):\n",
    "        for j in range(max(0, y - 1), min(grid.shape[1], y + 2)):\n",
    "            if (i, j) != (x, y):\n",
    "                neighbors.append(grid[i, j])\n",
    "    return neighbors\n",
    "\n",
    "def update_cell(x, y, criminality, education, income): # Update the criminality of a cell based on its neighbours nad itself\n",
    "\n",
    "    current_state = criminality[x, y]\n",
    "    neighbors = moore_neighbors(x, y, criminality) # Get the 8 neighbours of the cell\n",
    "    diff_list = neighbors - current_state\n",
    "\n",
    "    # Here we calculate the new criminality of the cell based on the criminality of the cell itself and the influence of the neighbours\n",
    "    new_state = (\n",
    "        current_state +\n",
    "        (sum(diff / (1 + sensitivity[x, y]) if diff > 0 else diff for diff in diff_list)) / 8\n",
    "    )\n",
    "    return np.clip(new_state, 0, 1)\n",
    "\n",
    "def update_grid(criminality, education, income): # Update the criminality of the whole grid based on the update_cell function\n",
    "    new_criminality = np.zeros_like(criminality)\n",
    "    for x in range(grid_size[0]):\n",
    "        for y in range(grid_size[1]):\n",
    "            new_criminality[x, y] = update_cell(x, y, criminality, education, income)\n",
    "    return new_criminality\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation and output the results as animation\n",
    "\n",
    "def animate(t): # Define function to use in FuncAnimation (update grid for every timestep)\n",
    "    global criminality\n",
    "    criminality, mask = update_grid_withpolice(criminality, education, income, influence_diff, police_threshold, police_effect, redistribution_frac, police_units)\n",
    "\n",
    "    # Save the layer with the criminality levels\n",
    "    cax.set_array(criminality)\n",
    "\n",
    "    # Save the layer with the police intervention\n",
    "    mask_layer = np.zeros((*grid_size, 4))\n",
    "    mask_layer[mask] = [0, 1, 0, 1] # Set the color of the police intervention to red and set the transparency to 0.5\n",
    "    overlay_cax.set_data(mask_layer)\n",
    "    return cax, overlay_cax\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.imshow(criminality, cmap='plasma', vmin=0, vmax=1)\n",
    "overlay_cax = ax.imshow(np.zeros((*grid_size, 4)))\n",
    "fig.colorbar(cax, ax=ax)\n",
    "ax.set_title('Criminality')\n",
    "\n",
    "timesteps = 30\n",
    "\n",
    "ani = FuncAnimation(fig, animate, frames=timesteps, interval=500)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the size of the giant component for different values of influence difference between \"good\" and \"bad\" neighbourhoods (without police)\n",
    "\n",
    "timesteps = 70\n",
    "influence_diff_list = np.linspace(-beta/2, beta/2, 30) # Define the range of influence difference (of \"bad\" influence compared to the \"good\" one) to study the emergence of the giant component\n",
    "average_giant_fractions = []\n",
    "init_criminality = np.random.rand(*grid_size)\n",
    "\n",
    "for i in range(5): # Repeat the simulation a few times to get an average curve for the emergence graph\n",
    "    giant_fractions = []\n",
    "    for influence_diff in influence_diff_list: # Loop through the influence difference values\n",
    "        criminality = init_criminality # Reset the criminality grid\n",
    "        for t in range(timesteps): # Run the simulation for a long enough time\n",
    "            criminality = update_grid_nopolice(criminality, education, income,influence_diff)\n",
    "        giant_fractions.append(giant_component(criminality, percolation_threshold)) # Get the size of the giant component\n",
    "    average_giant_fractions.append(giant_fractions) # Store the giant component sizes for every influence difference value\n",
    "\n",
    "average_giant_fractions = np.mean(average_giant_fractions, axis=0) # Compute the average giant component size for every influence difference value\n",
    "\n",
    "# Plot the size of the giant component after the fixed amount of timesteps (and a fixed threshold) for every influence difference value\n",
    "plt.plot(influence_diff_list, average_giant_fractions)\n",
    "plt.title('Emergence of Giant Component')\n",
    "plt.xlabel('Difference in Influence')\n",
    "plt.ylabel('Fraction of Giant Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the size of the giant component for different values of influence difference between \"good\" and \"bad\" neighbourhoods (with police)\n",
    "\n",
    "timesteps = 70\n",
    "influence_diff_list = np.linspace(-beta/2, beta/2, 30) # Define the range of influence difference (of \"bad\" influence compared to the \"good\" one) to study the emergence of the giant component\n",
    "average_giant_fractions = []\n",
    "init_criminality = np.random.rand(*grid_size)\n",
    "\n",
    "for i in range(5): # Repeat the simulation a few times to get an average curve for the emergence graph\n",
    "    giant_fractions = []\n",
    "    for influence_diff in influence_diff_list: # Loop through the influence difference values\n",
    "        criminality = init_criminality # Reset the criminality grid\n",
    "        for t in range(timesteps): # Run the simulation for a long enough time\n",
    "            criminality, mask = update_grid_withpolice(criminality, education, income, influence_diff, police_threshold, police_effect, redistribution_frac, police_units)\n",
    "        giant_fractions.append(giant_component(criminality, percolation_threshold)) # Get the size of the giant component\n",
    "    average_giant_fractions.append(giant_fractions) # Store the giant component sizes for every influence difference value\n",
    "\n",
    "average_giant_fractions = np.mean(average_giant_fractions, axis=0) # Compute the average giant component size for every influence difference value\n",
    "\n",
    "# Plot the size of the giant component after the fixed amount of timesteps (and a fixed threshold) for every influence difference value\n",
    "plt.plot(influence_diff_list, average_giant_fractions)\n",
    "plt.title('Emergence of Giant Component')\n",
    "plt.xlabel('Difference in Influence')\n",
    "plt.ylabel('Fraction of Giant Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the size of the giant component for different values of police threshold\n",
    "\n",
    "timesteps = 70\n",
    "influence_diff = 0\n",
    "police_threshold_list = np.linspace(0.4, 0.9, 30) # Define the range of police threshold values to study the emergence of the giant component\n",
    "average_giant_fractions = []\n",
    "init_criminality = np.random.rand(*grid_size)\n",
    "\n",
    "for i in range(5): # Repeat the simulation a few times to get an average curve for the emergence graph\n",
    "    giant_fractions = []\n",
    "    for police_threshold in police_threshold_list: # Loop through the police threshold values\n",
    "        criminality = init_criminality # Reset the criminality grid\n",
    "        for t in range(timesteps): # Run the simulation for a long enough time\n",
    "            criminality, mask = update_grid_withpolice(criminality, education, income,influence_diff, police_threshold, police_effect, redistribution_frac, police_units)\n",
    "        giant_fractions.append(giant_component(criminality, percolation_threshold)) # Get the size of the giant component\n",
    "    average_giant_fractions.append(giant_fractions) # Store the giant component sizes for every police threshold value\n",
    "\n",
    "average_giant_fractions = np.mean(average_giant_fractions, axis=0) # Compute the average giant component size for every police threshold value\n",
    "\n",
    "# Plot the size of the giant component after the fixed amount of timesteps (and a fixed threshold) for every police threshold value\n",
    "plt.plot(police_threshold_list, average_giant_fractions)\n",
    "plt.title('Emergence of Giant Component')\n",
    "plt.xlabel('Police Threshold')\n",
    "plt.ylabel('Fraction of Giant Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study avenache-size frequency distribution for threshold = 0.3\n",
    "\n",
    "# Initialize the grids\n",
    "criminality = np.random.rand(*grid_size)\n",
    "education = np.random.rand(*grid_size)\n",
    "income = np.random.rand(*grid_size)\n",
    "\n",
    "all_avelanches_sizes = track_avalanches(criminality, education, income, influence_diff, time_steps = 3000, threshold = 0.3) # Track all the avelancehs events and their sizes\n",
    "sizes, counts = np.unique(all_avelanches_sizes, return_counts=True) # Extract the size and number of events per size\n",
    "frequencies = counts / np.sum(counts) # Compute the frequency of each size\n",
    "\n",
    "plt.plot(sizes, frequencies)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('Avalanche Size Distribution')\n",
    "plt.xlabel('Size of Avalanche')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study avenache-size frequency distribution for threshold = 0.3\n",
    "\n",
    "side_lenght = [30, 50, 70, 90]\n",
    "time_steps = 4000\n",
    "threshold = 0.3\n",
    "all_sizes = []\n",
    "all_frequencies = []\n",
    "\n",
    "for side in side_lenght:\n",
    "    grid_size = (side, side)\n",
    "    # Initialize the grids\n",
    "    criminality = np.random.rand(*grid_size)\n",
    "    education = np.random.rand(*grid_size)\n",
    "    income = np.random.rand(*grid_size)\n",
    "\n",
    "    all_avelanches_sizes = track_avalanches(criminality, education, income, influence_diff, time_steps, threshold) # Track all the avelancehs events and their sizes\n",
    "    sizes, counts = np.unique(all_avelanches_sizes, return_counts=True) # Extract the size and number of events per size\n",
    "    frequencies = counts / np.sum(counts) # Compute the frequency of each size\n",
    "\n",
    "    all_sizes.append(sizes)\n",
    "    all_frequencies.append(frequencies)\n",
    "\n",
    "    plt.plot(sizes, frequencies)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.title(f'Avalanche Size Distribution on a {side}x{side} grid')\n",
    "    plt.xlabel('Size of Avalanche')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_sizes = []\n",
    "scaled_frequencies = []\n",
    "D = 0.1\n",
    "tau = 0.8\n",
    "\n",
    "for sizes, frequencies, side in zip(all_sizes, all_frequencies, side_lenght):\n",
    "    scaled_sizes.append(sizes / (side ** D))\n",
    "    scaled_frequencies.append(frequencies * (side ** tau))\n",
    "\n",
    "for scaled_size, scaled_frequency, side in zip(scaled_sizes, scaled_frequencies, side_lenght):\n",
    "    plt.plot(scaled_size, scaled_frequency, label=f'{side}x{side}')\n",
    "\n",
    "plt.title('Data Collapse of Avalanche Size Distribution')\n",
    "plt.xlabel('Scaled Avelanche Size (s / L^D)')\n",
    "plt.ylabel('Scaled Frequency (P(s) * L^tau)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
